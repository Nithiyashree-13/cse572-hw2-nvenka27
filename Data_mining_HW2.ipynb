{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer, KNNImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "\n",
        "\n",
        "DATA_PATH = Path(\"/content/train.csv\")\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "\n",
        "TARGET = \"Survived\"\n",
        "y = df[TARGET].values\n",
        "X_raw = df.drop(columns=[TARGET])\n",
        "\n",
        "\n",
        "class TitanicFeatureBuilder(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Add Title, FamilySize, IsAlone. Keep all original columns; downstream\n",
        "    ColumnTransformer selects what it needs and drops the rest.\"\"\"\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        def extract_title(name):\n",
        "            m = re.search(r\",\\s*([^\\.]+)\\.\", str(name))\n",
        "            return m.group(1).strip() if m else \"None\"\n",
        "\n",
        "        title = X[\"Name\"].map(extract_title)\n",
        "        title = title.replace(\n",
        "            {\n",
        "                \"Mlle\": \"Miss\", \"Ms\": \"Miss\", \"Mme\": \"Mrs\",\n",
        "                \"Lady\": \"Royal\", \"Countess\": \"Royal\", \"Sir\": \"Royal\",\n",
        "                \"Jonkheer\": \"Royal\", \"Don\": \"Royal\", \"Dona\": \"Royal\",\n",
        "                \"Dr\": \"Officer\", \"Rev\": \"Officer\", \"Col\": \"Officer\",\n",
        "                \"Major\": \"Officer\", \"Capt\": \"Officer\"\n",
        "            }\n",
        "        )\n",
        "        X[\"Title\"] = title\n",
        "\n",
        "\n",
        "        X[\"FamilySize\"] = X[\"SibSp\"].fillna(0) + X[\"Parch\"].fillna(0) + 1\n",
        "        X[\"IsAlone\"] = (X[\"FamilySize\"] == 1).astype(int)\n",
        "\n",
        "        return X\n",
        "\n",
        "feat_builder = TitanicFeatureBuilder()\n",
        "\n",
        "numeric_features = [\"Age\", \"SibSp\", \"Parch\", \"Fare\", \"FamilySize\", \"IsAlone\"]\n",
        "categorical_features = [\"Pclass\", \"Sex\", \"Embarked\", \"Title\"]\n",
        "\n",
        "numeric_transformer_median = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"scaler\", StandardScaler(with_mean=False)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "numeric_transformer_knn = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", KNNImputer(n_neighbors=5, weights=\"uniform\")),\n",
        "        (\"scaler\", StandardScaler(with_mean=False)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "categorical_transformer = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "def make_preprocessor(numeric_transformer):\n",
        "    return ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", numeric_transformer, numeric_features),\n",
        "            (\"cat\", categorical_transformer, categorical_features),\n",
        "        ],\n",
        "        remainder=\"drop\"\n",
        "    )\n",
        "\n",
        "pipe = Pipeline(\n",
        "    steps=[\n",
        "        (\"feat\", feat_builder),\n",
        "        (\"preprocess\", make_preprocessor(numeric_transformer_median)),\n",
        "        (\"clf\", DecisionTreeClassifier(random_state=42))\n",
        "    ]\n",
        ")\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "param_grid = [\n",
        "    {\n",
        "        \"preprocess\": [make_preprocessor(numeric_transformer_median)],\n",
        "        \"clf__criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
        "        \"clf__max_depth\": [3, 5, 6, 7, 9, 11],\n",
        "        \"clf__min_samples_split\": [2, 5, 10],\n",
        "        \"clf__min_samples_leaf\": [1, 2, 4],\n",
        "    },\n",
        "    {\n",
        "        \"preprocess\": [make_preprocessor(numeric_transformer_knn)],\n",
        "        \"clf__criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
        "        \"clf__max_depth\": [3, 5, 6, 7, 9, 11],\n",
        "        \"clf__min_samples_split\": [2, 5, 10],\n",
        "        \"clf__min_samples_leaf\": [1, 2, 4],\n",
        "    },\n",
        "]\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=pipe,\n",
        "    param_grid=param_grid,\n",
        "    scoring=\"accuracy\",\n",
        "    cv=cv,\n",
        "    n_jobs=-1,\n",
        "    verbose=1,\n",
        "    refit=True,\n",
        "    return_train_score=True,\n",
        ")\n",
        "\n",
        "grid.fit(X_raw, y)\n",
        "\n",
        "best_model = grid.best_estimator_\n",
        "best_params = grid.best_params_\n",
        "best_cv = grid.best_score_\n",
        "\n",
        "print(\"\\n=== Decision Tree (tuned) ===\")\n",
        "print(f\"Best 5-fold CV accuracy: {best_cv:.4f}\")\n",
        "print(\"Best params:\")\n",
        "for k, v in best_params.items():\n",
        "    print(f\"  {k}: {v}\")\n",
        "\n",
        "clf = best_model.named_steps[\"clf\"]\n",
        "preprocessor = best_model.named_steps[\"preprocess\"]\n",
        "\n",
        "try:\n",
        "    feat_names = preprocessor.get_feature_names_out()\n",
        "except AttributeError:\n",
        "    num_names = numeric_features\n",
        "    cat_ohe = preprocessor.named_transformers_[\"cat\"].named_steps[\"ohe\"]\n",
        "    cat_names = cat_ohe.get_feature_names_out(categorical_features).tolist()\n",
        "    feat_names = np.array(list(num_names) + cat_names)\n",
        "\n",
        "plt.figure(figsize=(22, 12))\n",
        "plot_tree(\n",
        "    clf,\n",
        "    feature_names=feat_names,\n",
        "    class_names=[\"Not Survived\", \"Survived\"],\n",
        "    filled=True,\n",
        "    rounded=True,\n",
        "    fontsize=9,\n",
        ")\n",
        "plt.title(\"Titanic — Tuned Decision Tree\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"titanic_decision_tree.png\", dpi=220)\n",
        "plt.close()\n",
        "print(\"Saved tree plot to titanic_decision_tree.png\")\n",
        "print(f\"Tree depth: {clf.get_depth()} | Leaves: {clf.get_n_leaves()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCJ8TruKmjKS",
        "outputId": "3aefee93-ce66-4c55-d9ce-8061f114135f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
            "\n",
            "=== Decision Tree (tuned) ===\n",
            "Best 5-fold CV accuracy: 0.8283\n",
            "Best params:\n",
            "  clf__criterion: entropy\n",
            "  clf__max_depth: 3\n",
            "  clf__min_samples_leaf: 1\n",
            "  clf__min_samples_split: 2\n",
            "  preprocess: ColumnTransformer(transformers=[('num',\n",
            "                                 Pipeline(steps=[('imputer',\n",
            "                                                  SimpleImputer(strategy='median')),\n",
            "                                                 ('scaler',\n",
            "                                                  StandardScaler(with_mean=False))]),\n",
            "                                 ['Age', 'SibSp', 'Parch', 'Fare', 'FamilySize',\n",
            "                                  'IsAlone']),\n",
            "                                ('cat',\n",
            "                                 Pipeline(steps=[('imputer',\n",
            "                                                  SimpleImputer(strategy='most_frequent')),\n",
            "                                                 ('ohe',\n",
            "                                                  OneHotEncoder(handle_unknown='ignore',\n",
            "                                                                sparse_output=False))]),\n",
            "                                 ['Pclass', 'Sex', 'Embarked', 'Title'])])\n",
            "Saved tree plot to titanic_decision_tree.png\n",
            "Tree depth: 3 | Leaves: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "base_rf = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    bootstrap=True, oob_score=False,\n",
        "    n_jobs=-1, random_state=42\n",
        ")\n",
        "\n",
        "eval_pipe_rf = Pipeline([\n",
        "    (\"feat\", feat_builder),\n",
        "    (\"preprocess\", best_model.named_steps[\"preprocess\"]),\n",
        "    (\"clf\", base_rf),\n",
        "])\n",
        "\n",
        "cv3 = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "param_dist = {\n",
        "    \"clf__max_depth\": [None, 10],\n",
        "    \"clf__min_samples_split\": randint(2, 11),\n",
        "    \"clf__min_samples_leaf\": randint(1, 4),\n",
        "    \"clf__max_features\": [\"sqrt\", 0.5],\n",
        "    \"clf__class_weight\": [None, \"balanced\"],\n",
        "}\n",
        "\n",
        "rs = RandomizedSearchCV(\n",
        "    eval_pipe_rf, param_distributions=param_dist,\n",
        "    n_iter=40, scoring=\"accuracy\", cv=cv3, n_jobs=-1, verbose=1, random_state=42, refit=True\n",
        ")\n",
        "rs.fit(X_raw, y)\n",
        "\n",
        "print(\"Fast tuned RF (3-fold) best:\", rs.best_score_, rs.best_params_)\n",
        "\n",
        "best_rf = rs.best_estimator_\n",
        "best_rf.named_steps[\"clf\"].set_params(n_estimators=800, oob_score=True)\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(best_rf, X_raw, y, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
        "print(f\"Final RF 5-fold: {scores.mean():.4f} ± {scores.std():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywUlt3VQ1ybb",
        "outputId": "f17a7956-ddac-4841-dd98-8426072a60c7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n",
            "Fast tuned RF (3-fold) best: 0.8451178451178452 {'clf__class_weight': None, 'clf__max_depth': None, 'clf__max_features': 0.5, 'clf__min_samples_leaf': 3, 'clf__min_samples_split': 8}\n",
            "Final RF 5-fold: 0.8406 ± 0.0240\n"
          ]
        }
      ]
    }
  ]
}